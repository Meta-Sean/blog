[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Greetings traveler, my name is terps and I will be your guide today. Blogging about stuff I donâ€™t know so I can get to know it better ðŸ˜…. Blog mainly focused on machine learning / deep learning and drawing insights from data. Interested in meta-skills: decision making & problem solving. Thanks for visiting you can reach me at admin@terpsfi.xyz if you wanna chat."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "jupyter\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\nTerps\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html",
    "href": "posts/micrograd/2022-10-07-micrograd.html",
    "title": "Micrograd ðŸ”§",
    "section": "",
    "text": "Spelled-out intro to neural networks and backpropagation"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#now-we-will-recurse-our-way-backwards-again-and-going-to-do-our-second-application-of-the-chain-rule",
    "href": "posts/micrograd/2022-10-07-micrograd.html#now-we-will-recurse-our-way-backwards-again-and-going-to-do-our-second-application-of-the-chain-rule",
    "title": "Micrograd ðŸ”§",
    "section": "Now we will recurse our way backwards again and going to do our second application of the chain rule",
    "text": "Now we will recurse our way backwards again and going to do our second application of the chain rule\n\n\\(\\frac{dL}{de} = -2.0\\) \n\n\n\\(\\frac{de}{da} = b\\) \n\n\n\\(\\frac{dL}{da} = \\frac{dL}{de} * \\frac{de}{da}\\)\nWe are multiplying the derivative of e with respect to L with the local gradients\n\na.grad = -2.0 * -3.0\nb.grad = -2.0 * 2.0\n\n\ndraw_dot(L)\n\n\n\n\nLets verify\n\ndef lol():\n    \n    h = 0.0001\n    \n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n    \n    # this is the variable we are nudging by h\n    a = Value(2.0 , label='a')\n    a.data += h\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n    \n    print((L2-L1)/h)\nlol()\n\n6.000000000021544\n\n\nChecks out"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#we-know-know-what-back-propagation-is-a-recursive-application-of-the-chain-rule-backwards-through-the-computational-graph",
    "href": "posts/micrograd/2022-10-07-micrograd.html#we-know-know-what-back-propagation-is-a-recursive-application-of-the-chain-rule-backwards-through-the-computational-graph",
    "title": "Micrograd ðŸ”§",
    "section": "We know know what back propagation is; a recursive application of the chain rule backwards through the computational graph",
    "text": "We know know what back propagation is; a recursive application of the chain rule backwards through the computational graph"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#neuron-example",
    "href": "posts/micrograd/2022-10-07-micrograd.html#neuron-example",
    "title": "Micrograd ðŸ”§",
    "section": "Neuron Example",
    "text": "Neuron Example\nOne step optimization\n\na.data += 0.01 * a.grad\nb.data += 0.01 * b.grad\nc.data += 0.01 * c.grad\nf.data += 0.01 * f.grad\n\ne = a * b\nd = e + c\nL = d * f\n\nprint(L.data)\n\n-7.286496\n\n\n\nFor our model of neurons we have input axis and these synapses that have weights on them so the wâ€™s are the weights and then the synapse interacts with the input multiplicatively so what flows to the cell body of this neuron is w times x but thereâ€™s multiple inputs so thereâ€™s many w times xâ€™s flowing into the cell body, the cell body also has some bias which is a sort of trigger happiness of this neuron, making it more or less prone to firing. Then we take it through an activation function which is generally some kinda of squashing function like a sigmoid or tanh. Lets go over an example of a tanh activation function\n\nplt.plot(np.arange(-5, 5, 0.2), np.tanh(np.arange(-5, 5, 0.2))); plt.grid();\n\n\n\n\nYou can see that the inputs that come in get squashed here on the y axis, the function gets capped at 1.00 and -1.00\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\ndraw_dot(n)\n\n\n\n\nWe need to add more operations to our Value class to be able to calculate our activation function tanh, lets just do a cheeky implementation of tanh on our value class for now\n\nclass Value:\n    \n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n        self.grad = 0.0\n        \n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    \n    def __add__(self, other):\n        out = Value(self.data + other.data, (self, other), '+')\n        return out \n    \n    def __mul__(self, other):\n        out = Value(self.data * other.data, (self, other), '*')\n        return out\n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        return out\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\ndraw_dot(n)\n\n\n\n\n\no = n.tanh(); o.label = 'o'\n\n\ndraw_dot(o)\n\n\n\n\nAwesome n goes through tanh to produce the last output, our activation function is working great, now all we need to know is the derivative of tanh and we can use backpropagation.\n\no.grad = 1.0\n\nLets calculte the gradient of n\n\n1 - o.data**2\n\n0.4999999999999999\n\n\n\nn.grad = 0.5\n\nNow we can easily get the gradients for x1w1x2w1, b, x1w1, x2w2 since we used addition as an operation the local derivatives are just 1 so we just take the value 0.5\n\nx1w1x2w2.grad = 0.5\nb.grad = 0.5\nx1w1.grad = 0.5\nx2w2.grad = 0.5\n\nWe can know calculate the gradients for x2, w2, x1, and w1, but unlike the last gradients we used multiplication as our operation, so our local derivative is just the other term used in the operation so lets calculate the gradients\n\nx2.grad = w2.data * x2w2.grad\nw2.grad = x2.data * x2w2.grad\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n\n\ndraw_dot(o)\n\n\n\n\nNice!, we have manually used backpropagation to calculate our gradients, now lets implement a backward function for each operation"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#fx-3x2---4x-5",
    "href": "posts/micrograd/2022-10-07-micrograd.html#fx-3x2---4x-5",
    "title": "Micrograd ðŸ”§",
    "section": "\\(f(x) = 3x^2 - 4x + 5\\)",
    "text": "\\(f(x) = 3x^2 - 4x + 5\\)\n\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n\nf(3.0)\n\n20.0\n\n\nTake a look at the shape of the function, we can expect a parabola since we know its a quadratic function\n\n# creating a range of x values from -5 to 5 incrementing by 0.25 to pass into our function to generate our y values\nxs = np.arange(-5, 5, 0.25)\nys = f(xs)\nplt.plot(xs, ys)\n\n\n\n\nWe know want to think through what is the derivative of this function at different points x, let refresh with the definition of a derivative ## \\(f'(x) = lim_{h \\to 0} \\frac{f(x+h)-f(x)}{h}\\)\nYou are basically trying to see the level of sensitivty the function responds with by bumping any x value at any point slightly by this small number h  Intuitively how would you expect this function to respond if we nudged x = 3.0 by this small postitive number h? The amount the x value responds tells you the strength of the slope\n\nh = 0.0001\nx = 3.0\nprint(f'slope of function at x = {x}, slope = {(f(x + h) - f(x)) / h}')\n\nslope of function at x = 3.0, slope = 14.000300000063248\n\n\nLets do a hacky implementation with more variables  Look at the function a*b + c in relation to the variables we assigned, imagine if you nudged each variables by a tiny amount would that result in our output being increased or decreased?  If we were to slightly nudge each of our input varibles by the tiny amount h(amount approaching 0) we can approximate the instataneous rate of change by looking at the difference before and after over the amount we nudged by, this will give us the slope.\n\n# lets get more complex\nh = 0.0001\n#inputs\na = 2.0\nb = -3.0\nc = 10.0\n\n#We wanna find the derivative of d with respect to a,b,c\nd1 = a*b + c\na +=  h\nd2 = a*b + c\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 4.0\nd2 3.999699999999999\nslope -3.000000000010772\n\n\nLets do it with b now\n\nd1 = a*b + c\nb +=  h\nd2 = a*b + c\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 3.999699999999999\nd2 3.99990001\nslope 2.0001000000124947\n\n\nAnd câ€¦\n\nd1 = a*b + c\nc +=  h\nd2 = a*b + c\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 3.99990001\nd2 4.00000001\nslope 0.9999999999976694\n\n\nHopefully this has helped build an inuitive sense of what this derivative is telling you about the function, but now we want to move to neural networks, which will be massive mathmatical expressions, so we need some structures to maintain these expressions, so we will build out a value object that can keep track of state and allow us to do expressions"
  }
]