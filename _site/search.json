[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Greetings traveler, my name is terps and I will be your guide today. Blogging about stuff I donâ€™t know so I can get to know it better ðŸ˜…. Blog mainly focused on machine learning / deep learning and drawing insights from data. Interested in meta-skills: decision making & problem solving. Thanks for visiting you can reach me at admin@terpsfi.xyz if you wanna chat."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "jupyter\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\nTerps\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html",
    "href": "posts/micrograd/2022-10-07-micrograd.html",
    "title": "Micrograd ðŸ”§",
    "section": "",
    "text": "Spelled-out intro to neural networks and backpropagation"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#now-we-will-recurse-our-way-backwards-again-and-going-to-do-our-second-application-of-the-chain-rule",
    "href": "posts/micrograd/2022-10-07-micrograd.html#now-we-will-recurse-our-way-backwards-again-and-going-to-do-our-second-application-of-the-chain-rule",
    "title": "Micrograd ðŸ”§",
    "section": "Now we will recurse our way backwards again and going to do our second application of the chain rule",
    "text": "Now we will recurse our way backwards again and going to do our second application of the chain rule\n\n\\(\\frac{dL}{de} = -2.0\\) \n\n\n\\(\\frac{de}{da} = b\\) \n\n\n\\(\\frac{dL}{da} = \\frac{dL}{de} * \\frac{de}{da}\\)\nWe are multiplying the derivative of e with respect to L with the local gradients\n\na.grad = -2.0 * -3.0\nb.grad = -2.0 * 2.0\n\n\ndraw_dot(L)\n\n\n\n\nLets verify\n\ndef lol():\n    \n    h = 0.0001\n    \n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n    \n    # this is the variable we are nudging by h\n    a = Value(2.0 , label='a')\n    a.data += h\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n    \n    print((L2-L1)/h)\nlol()\n\n6.000000000021544\n\n\nChecks out"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#we-know-know-what-back-propagation-is-a-recursive-application-of-the-chain-rule-backwards-through-the-computational-graph",
    "href": "posts/micrograd/2022-10-07-micrograd.html#we-know-know-what-back-propagation-is-a-recursive-application-of-the-chain-rule-backwards-through-the-computational-graph",
    "title": "Micrograd ðŸ”§",
    "section": "We know know what back propagation is; a recursive application of the chain rule backwards through the computational graph",
    "text": "We know know what back propagation is; a recursive application of the chain rule backwards through the computational graph"
  },
  {
    "objectID": "posts/micrograd/2022-10-07-micrograd.html#neuron-example",
    "href": "posts/micrograd/2022-10-07-micrograd.html#neuron-example",
    "title": "Micrograd ðŸ”§",
    "section": "Neuron Example",
    "text": "Neuron Example\nOne step optimization\n\na.data += 0.01 * a.grad\nb.data += 0.01 * b.grad\nc.data += 0.01 * c.grad\nf.data += 0.01 * f.grad\n\ne = a * b\nd = e + c\nL = d * f\n\nprint(L.data)\n\n-7.286496\n\n\n\n\n\nimage.png\n\n\nFor our model of neurons we have input axis and these synapses that have weights on them so the wâ€™s are the weights and then the synapse interacts with the input multiplicatively so what flows to the cell body of this neuron is w times x but thereâ€™s multiple inputs so thereâ€™s many w times xâ€™s flowing into the cell body, the cell body also has some bias which is a sort of trigger happiness of this neuron, making it more or less prone to firing. Then we take it through an activation function which is generally some kinda of squashing function like a sigmoid or tanh. Lets go over an example of a tanh activation function\n\nplt.plot(np.arange(-5, 5, 0.2), np.tanh(np.arange(-5, 5, 0.2))); plt.grid();\n\n\n\n\nYou can see that the inputs that come in get squashed here on the y axis, the function gets capped at 1.00 and -1.00\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\ndraw_dot(n)\n\n\n\n\nWe need to add more operations to our Value class to be able to calculate our activation function tanh, lets just do a cheeky implementation of tanh on our value class for now\n\nclass Value:\n    \n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n        self.grad = 0.0\n        \n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    \n    def __add__(self, other):\n        out = Value(self.data + other.data, (self, other), '+')\n        return out \n    \n    def __mul__(self, other):\n        out = Value(self.data * other.data, (self, other), '*')\n        return out\n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        return out\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\ndraw_dot(n)\n\n\n\n\n\no = n.tanh(); o.label = 'o'\n\n\ndraw_dot(o)\n\n\n\n\nAwesome n goes through tanh to produce the last output, our activation function is working great, now all we need to know is the derivative of tanh and we can use backpropagation.\n\no.grad = 1.0\n\nLets calculte the gradient of n\n\n1 - o.data**2\n\n0.4999999999999999\n\n\n\nn.grad = 0.5\n\nNow we can easily get the gradients for x1w1x2w1, b, x1w1, x2w2 since we used addition as an operation the local derivatives are just 1 so we just take the value 0.5\n\nx1w1x2w2.grad = 0.5\nb.grad = 0.5\nx1w1.grad = 0.5\nx2w2.grad = 0.5\n\nWe can know calculate the gradients for x2, w2, x1, and w1, but unlike the last gradients we used multiplication as our operation, so our local derivative is just the other term used in the operation so lets calculate the gradients\n\nx2.grad = w2.data * x2w2.grad\nw2.grad = x2.data * x2w2.grad\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n\n\ndraw_dot(o)\n\n\n\n\nNice!, we have manually used backpropagation to calculate our gradients, now lets implement a backward function for each operation\n # Backward Function\nLets add a backward methods to our Value object for each operation that we can call to calculate our gradients for us using backpropagation\n\nclass Value:\n    \n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n        self.grad = 0.0\n        self._backward = lambda: None\n        \n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    \n    def __add__(self, other):\n        out = Value(self.data + other.data, (self, other), '+')\n        \n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        out._backward = _backward\n        \n        return out \n    \n    def __mul__(self, other):\n        out = Value(self.data * other.data, (self, other), '*')\n                \n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        \n        return out\n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        \n        def _backward():\n            self.grad += (1 - t**2) * out.grad\n        out._backward = _backward\n        \n        return out\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\ndraw_dot(o)\n\n\n\n\nWe initialize the gradient of o to 1.0, then call _backward to recursively calculate the gradients\n\no.grad = 1.0\n\n\no._backward()\n\n\ndraw_dot(o)\n\n\n\n\n\nn._backward()\nb._backward()\nx1w1x2w2._backward()\nx2w2._backward()\nx1w1._backward()\n\n\ndraw_dot(o)\n\n\n\n\nAwesome, this works great, we never want to call backward() on a node before we have calculated the gradients for everthing after it since it depends on their gradients. We will use topological sort which lays the graph such that all the edges go only from left to right.\n\n\n\nimg.png\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\n#6.8813735870195432\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\ndraw_dot(o)\n\n\n\n\n\n# topological sort\ntopo = []\nvisited = set()\ndef build_topo(v):\n    if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n            build_topo(child)\n        topo.append(v)\nbuild_topo(o)\ntopo\n\n[Value(data=1.0),\n Value(data=0.0),\n Value(data=0.0),\n Value(data=2.0),\n Value(data=-3.0),\n Value(data=-6.0),\n Value(data=-6.0),\n Value(data=6.881373587019543),\n Value(data=0.8813735870195432),\n Value(data=0.7071067811865476)]\n\n\nOur Value objects are now ordered properly\n\no.grad = 1.0\n\n\nfor node in reversed(topo):\n    node._backward()\n\n\ndraw_dot(o)\n\n\n\n\n # Lets implement this as a method in the Value object and add more operations\n\nclass Value:\n    \n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n        self.grad = 0.0\n        self._backward = lambda: None\n        \n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    \n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        \n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        out._backward = _backward\n        \n        return out \n    \n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n                \n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        \n        return out\n    \n    def __rmul__(self, other):\n        return self * other\n    \n    def __truediv__(self, other):\n        return self * other**-1\n    \n    def __neg__(self): # -self\n        return self * -1\n    \n    def __sub__(self, other): # self - other\n        return self + (-other)\n    \n    def __radd__(self, other): # other + self\n        return self + other\n    \n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n\n        def _backward():\n            self.grad += other * (self.data ** (other - 1)) * out.grad\n        out._backward = _backward\n\n        return out\n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        \n        def _backward():\n            self.grad += (1 - t**2) * out.grad\n        out._backward = _backward\n        \n        return out\n    \n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n\n        def _backward():\n          self.grad += out.data * out.grad \n        out._backward = _backward\n\n        return out\n    # Now we can call backward on our Value object\n    def backward(self):\n    \n        topo = []\n        visited = set()\n        def build_topo(v):\n          if v not in visited:\n            visited.add(v)\n            for child in v._prev:\n              build_topo(child)\n            topo.append(v)\n        build_topo(self)\n\n        self.grad = 1.0\n        for node in reversed(topo):\n          node._backward()\n\n\na = Value(2.0)\nb = Value(4.0)\na - b\n\nValue(data=-2.0)\n\n\n\na = Value(2.0)\na.exp()\n\nValue(data=7.38905609893065)\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# ----\ne = (2*n).exp()\no = (e - 1) / (e + 1)\n# ----\no.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n # Pytorch comparison\n\nimport torch\n\nx1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\n\no\n\ntensor([0.7071], dtype=torch.float64, grad_fn=<TanhBackward0>)\n\n\n\no.item()\n\n0.7071066904050358\n\n\n\n\n\nimg.png\n\n\n\nimport random\n\n\nclass Neuron:\n  \n    def __init__(self, nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n  \n    def __call__(self, x):\n        # w * x + b\n        act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n        out = act.tanh()\n        return out\n    \n    def parameters(self):\n        return self.w + [self.b]\n\nclass Layer:\n    \n    def __init__(self, nin, nout):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n        \n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\n    \n    def parameters(self):\n        return [p for neuron in self.neurons for p in neuron.parameters()]\n#         params = []\n#         for neuron in self.neurons:\n#             ps = neuron.parameters()\n#             params.extend(ps)\n#         return params\n\nclass MLP:\n    \n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n        \n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n    \n    def parameters(self):\n        return [p for layer in self.layers for p in layer.parameters()]\n    \n\n\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n\nValue(data=-0.7028959990425087)\n\n\n\nlen(n.parameters())\n\n41\n\n\n\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\nys = [1.0, -1.0, -1.0, 1.0]\nypred = [n(x) for x in xs]\nypred\n\n[Value(data=-0.7028959990425087),\n Value(data=0.1757758058598642),\n Value(data=0.39624177470697325),\n Value(data=0.16264413106842704)]\n\n\nSo how do we tune the weights to better predict the desired targets? We calculate a single number that measures the total performance of the neural net, this is called the loss.\n\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=6.932959473871423)\n\n\n\nloss.backward()\n\nNow that we have called backward on the loss, we can take a look at the gradient of a single neuron in one of our layers to get a look on how it impacts our loss, this will be useful soon when we try to update our weights to decrease the loss\n\nn.layers[0].neurons[0].w[0].data\n\n0.28438888706081467\n\n\nThe gradient for this neuron is positive, so the weights is increasing our loss\n\nn.layers[0].neurons[0].w[0].grad\n\n1.711566891777295\n\n\n\nn.layers[0].neurons[0].b.grad\n\n1.0849775541180198\n\n\nWe can now also call draw_dot on our loss, we can see the DAG has increased tremendously in compelexity\n\ndraw_dot(loss)\n\n\n\n\nWe can update our parameters by multiplying by substracting them by their gradients multiplied by a learning rate (the desired impact of the gradient has in updating our parameters, here we use 0.01 arbitrarily, but there are many techniques to find an optimal learning rate and to decay the rate as training continues, 0.1 is also a good rule of thumb, too big and you can overstep too small and its costly to train\n\nfor p in n.parameters():\n    p.data -= 0.01 * p.grad    \n\n\nn.layers[0].neurons[0].w[0].data\n\n0.2672732181430417\n\n\nAfter updating our parameters we can confirm our loss decreased\n\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=6.317575661771169)\n\n\nWhat we have done is gradient decent. Forward pass -> backward pass -> update the parameters. Now we just have to iterate this process, lets turn this manual process into a training loop\n\nfor k in range(10):\n    \n    # forward pass\n    ypred = [n(x) for x in xs]\n    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n    \n    #backward pass\n    loss.backward()\n    \n    #update\n    for p in n.parameters():\n        p.data -= 0.05 * p.grad\n        p.grad = 0\n    print(k, loss.data)\n\n0 0.10345239945960188\n1 0.0941558588278075\n2 0.0862952014023131\n3 0.07956846088984432\n4 0.07375215882362336\n5 0.06867739459504289\n6 0.06421419054843136\n7 0.06026093580621215\n8 0.056737086525177276\n9 0.05357800634860667\n\n\n\nypred\n\n[Value(data=0.8741761793258574),\n Value(data=-0.8786120732704685),\n Value(data=-0.8952118169896238),\n Value(data=0.8903150856076475)]"
  }
]